# News-Impact-Analysis-of-Stock-Market-
# -*- coding: utf-8 -*-
"""news.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c1f5D73mrzmARWezC1BNYBZ_fCiOwQUy
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
data = pd.read_csv('/content/newsfeed - News (5).csv')
df=data.copy()

df['description'] = df ['Description']

import nltk
nltk.download('punkt')
df.dropna(subset=["Description"],inplace=True)
for i, row in df.iterrows():
  text = row["Description"]
  row["Description"] = nltk.word_tokenize(text)
print(i,df["Description"])

uploaded_2 = files.upload()

data_2 = pd.read_csv('/content/ticker.csv')
df2 = data_2.copy()

df['match']=df2['SYMBOL'] +" " + df2['NAME OF COMPANY']
df['SYMBOL'] = df2['SYMBOL']

import re

df['text'] = df['Title'].astype(str) + ' ' + df['Description'].astype(str)
def extract_company_name(text):
    pattern = r'\b(?:{})\b'.format('|'.join(df2['SYMBOL']))
    matches = re.findall(pattern, text, re.IGNORECASE)
    return str(set(matches))
df['common_company_names'] = df['text'].apply(extract_company_name)
df2['names'] = df2['SYMBOL'].astype(str) + ' ' + df2['NAME OF COMPANY'].astype(str)
common_company_names = set(df['common_company_names'].explode().unique()).intersection(set(df2['names'].unique()))
j=0
'''for i in df['common_company_names']:
  if(i):
    j=j+1
    print(j,i)'''
df.head(50)

!pip install fuzzywuzzy

!pip install python-Levenshtein

df2['match']=df2['SYMBOL'] +" " + df2['NAME OF COMPANY']
df['SYMBOL'] = df2['SYMBOL']

from fuzzywuzzy import fuzz

for i, row in df.iterrows():
    
    # Get the current common company name as a list
    current_common_name = str(row['common_company_names']).replace('{','').replace('}','').replace('\'','').split(';')
    
    # Loop through all other rows to find matches
    for j, other_row in df2.iterrows():
        
        # Ignore the current row
        if i == j:
            continue
        
        # Check if the common company name matches
        other_common_name = str(other_row['match']).replace('{','').replace('}','').replace('\'','').split(';')
        #if set(other_common_name) == set(current_common_name):
            # If the company names are similar enough, store the symbol in a new column
        name_similarity = fuzz.token_set_ratio(other_common_name,' '.join(current_common_name))
        if name_similarity >= 80:
           # change the threshold as required
          df.at[i, 'Matched Symbol'] = other_row['SYMBOL']

df['title'] = df['Title']
df['title'] = df['title'].str.split()
string = 'Adani Enterprises Limited ADANIENT'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ADANIENT'

string = 'Adani Green Energy Limited ADANIGREEN'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ADANIGREEN'

string = 'Adani Ports and Special Economic Zone Limited ADANIPORTS'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ADANIPORTS'

string = 'Adani Power Limited ADANIPOWER'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ADANIPOWER'

string = 'Adani Transmission Limited ADANITRANS'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ADANITRANS'

string = 'ICICI Bank Limited ICICIBANK'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'ICICIBANK'

string = 'IndusInd Bank Limited INDUSINDBK'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'INDUSINDBK'

string = 'Hindustan Aeronautics Limited HAL '
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'HAL'

string = 'Hindustan Zinc HCC'
for i,row in df.iterrows():
    common_from_title= str(row['title']).replace('{','').replace('}','').replace('\'','').split(';')
    common_company = str(string).replace('{','').replace('}','').replace('\'','').split(';')
    name_similarity = fuzz.token_set_ratio(common_from_title,' '.join(common_company))
    if name_similarity >= 80:
      df.at[i, 'Matched Symbol'] = 'HCC'

!pip install pandas-datareader

from pandas_datareader import data as pdr
import yfinance as yfin
import datetime as dt

yfin.pdr_override()
#mask=df['Matched Symbol'].notnull()
for index,row in df.iterrows():
  date = pd.to_datetime(row['Date'])
  date = date.date()
  '''if pd.isna(date):
    print(index,'dt is NaT')
  else:
    print(index,'dt is not NaT')'''
  start1 = date - pd.Timedelta(days=5)
  end1 = date
  start2 = date
  end2 = date + pd.Timedelta(days=5)
  start1=str(start1)
  end1=str(end1)
  start2=str(start2)
  end2=str(end2)

  #print(start)
  #print(end)
  x =pd.notna(row['Matched Symbol'])


  if (x):
    string1 = pdr.get_data_yahoo(str(x),start=start1,end=end1)
    df.loc[index,'before'] = string1['High'].mean()
    string2 = pdr.get_data_yahoo(str(x),start=start2,end=end2)
    df.loc[index,'after'] = string2['High'].mean()
    if df.loc[index,'before'] >  df.loc[index,'after']:
       df.loc[index,'impact']="loss"
       df.loc[index,'value']=-1
    elif df.loc[index,'before']< df.loc[index,'after']:
       df.loc[index,'impact']="gain"
       df.loc[index,'value']=1
    else :
       df.loc[index,'impact']="neutral"
       df.loc[index,'value']=0


   
        #df.loc[index,'impact'] = pdr.get_data_yahoo(x,start=start,end=end)
#df.head()

for index, row in df.iterrows():
    if pd.isna(df.loc[index, 'impact']):
        df = df.drop(index)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# load the data into a pandas DataFrame


# extract the input and output columns
X = df['description']
y = df['value']

# split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# create a text vectorizer
vectorizer = TfidfVectorizer()

# transform the text data into numerical vectors
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# train the model and make predictions
# ...

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# load the datasedf = pd.read_csv('data.csv')

# replace missing values with 0
df = df.fillna(0)

# split the dataset into training and testing sets
X = df['description'] # features
y = df['value'] # target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# create a text vectorizer to convert the string input into a numeric format
vectorizer = TfidfVectorizer()

# transform the text data into numerical vectors
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# train a random forest model
rfc = RandomForestClassifier(n_estimators=100, random_state=42)
rfc.fit(X_train, y_train)

# make predictions on the testing set
y_pred = rfc.predict(X_test)

# evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy*100,'%')

from sklearn.preprocessing import LabelEncoder

# load the dataset
#df = pd.read_csv('data.csv')

# create an instance of LabelEncoder
le = LabelEncoder()

# fit and transform the string column to numeric values
df['description'] = le.fit_transform(df['description'])

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

mpl.rcParams['font.family'] = 'serif'
mpl.rcParams['font.serif'] = ['Times New Roman'] + mpl.rcParams['font.serif']

# load the dataset
#df = pd.read_csv('data.csv')

# replace missing values with 0
df = df.fillna(0)

# plot a scatter plot using Seaborn
sns.scatterplot(data=df, x='description', y='impact')

# show the plot
plt.show()
